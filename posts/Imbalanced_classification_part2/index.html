<!DOCTYPE html><html lang="en" mode="light" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Imbalanced data classification part2 | Kwon_sun_cheol</title><meta name="generator" content="Jekyll v4.2.0" /><meta property="og:title" content="Imbalanced data classification part2" /><meta name="author" content="Kwon Suncheol" /><meta property="og:locale" content="en_US" /><meta name="description" content="A minimal, portfolio, sidebar, bootstrap Jekyll theme with responsive web design and focuses on text presentation." /><meta property="og:description" content="A minimal, portfolio, sidebar, bootstrap Jekyll theme with responsive web design and focuses on text presentation." /><link rel="canonical" href="https://classicmania.github.io/posts/Imbalanced_classification_part2/" /><meta property="og:url" content="https://classicmania.github.io/posts/Imbalanced_classification_part2/" /><meta property="og:site_name" content="Kwon_sun_cheol" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-01-24T00:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Imbalanced data classification part2" /><meta name="twitter:site" content="@twitter_username" /><meta name="twitter:creator" content="@Kwon Suncheol" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"headline":"Imbalanced data classification part2","description":"A minimal, portfolio, sidebar, bootstrap Jekyll theme with responsive web design and focuses on text presentation.","datePublished":"2021-01-24T00:00:00+09:00","dateModified":"2021-01-24T00:00:00+09:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://classicmania.github.io/posts/Imbalanced_classification_part2/"},"url":"https://classicmania.github.io/posts/Imbalanced_classification_part2/","author":{"@type":"Person","name":"Kwon Suncheol"},"@context":"https://schema.org"}</script><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="preload" as="style" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"><link rel="preload" as="style" href="/assets/css/post.css"><link rel="stylesheet" href="/assets/css/post.css"><link rel="preload" as="style" href="/assets/css/lib/bootstrap-toc.min.css"><link rel="stylesheet" href="/assets/css/lib/bootstrap-toc.min.css" /><link rel="preload" as="script" href="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4.0.0/dist/js/bootstrap.min.js" async></script> <script src="/assets/js/post.min.js" async></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" async></script> <script async src="https://www.googletagmanager.com/gtag/js?id="></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); </script> <script src="/app.js" defer></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column"><div id="nav-wrapper"><div id="profile-wrapper" class="d-flex flex-column"><div id="avatar" class="d-flex justify-content-center"> <a href="/" alt="avatar"> <img src="/assets/img/sample/polymath.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="profile-text mt-3"><div class="site-title"> <a href="/">Kwon_sun_cheol</a></div><div class="site-subtitle font-italic">Data lover</div></div></div><ul class="nav flex-column"><li class="nav-item d-flex justify-content-center "> <a href="/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item d-flex justify-content-center "> <a href="/tabs/categories/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item d-flex justify-content-center "> <a href="/tabs/tags/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item d-flex justify-content-center "> <a href="/tabs/archives/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item d-flex justify-content-center "> <a href="/tabs/about/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul></div><div class="sidebar-bottom d-flex flex-wrap justify-content-around mt-4"> <a href="https://github.com/classicmania" target="_blank"> <i class="fab fa-github-alt"></i> </a> <a href="https://classicmania33.medium.com/" target="_blank"> <i class="fab fa-medium"></i> </a> <a href="https://www.linkedin.com/in/%EC%88%9C%EC%B2%A0-%EA%B6%8C-9218a8180/" target="_blank"> <i class="fab fa-linkedin"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>Imbalanced data classification part2</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Imbalanced data classification part2</h1><div class="post-meta text-muted d-flex flex-column"><div> Posted <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Sun, Jan 24, 2021, 12:00 AM +0900" > Jan 24 <i class="unloaded">2021-01-24T00:00:00+09:00</i> </span> by <span class="author"> Kwon Suncheol </span></div></div><div class="post-content"><p><br /></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 " data-src="/assets/img/post_img/weight_image2.jpg" alt="weight_image2" /></p><p><br /></p><p>지난 포스트에 이어서 고객의 이탈 유무와 LTV를 예측하는 태스크를 진행할 때 <strong>‘불균형 데이터를 어떻게 다룰 것인가’에 관하여 숙고하였던 내용을 다루겠습니다.</strong></p><p>불균형 데이터는 데이터 자체의 크기, 노이즈를 유발하는 데이터, 왜도가 높은 데이터 분포 문제와 관련이 깊습니다. 지난 포스트에서 우리는 명쾌한 클래스의 분류(Ex : 이탈 또는 비이탈)와 실수로 표현되는 확률(Ex : 이탈 확률)간의 관계를 연결하는 Threshold와 관련된 다양한 Evaluation Metric이 존재하는 것을 확인할 수 있었습니다. 또한 기업 내부의 KPI와 집중하는 고객군이 어느 군(EX : 미래에 이탈을 할 고객군 VS 미래에 이탈을 하지 않을 고객군)인지에 따라 집중할 평가 지표가 다릅니다.</p><p><br /></p><h2 id="probability-scoring">Probability Scoring</h2><hr /><p>만약 비즈니스 관계자들과 유관부서가 명확한 클래스의 분류값이 아닌 확률값 자체를 원한다면 어떻게 대응해야 할까요?<br /> 이런 경우 ‘Threhold Metrics’이 아닌 새로운 확률값에 최적화된 Metric이 필요합니다. 확률 지표는 실제로 알려진 클래스의 확률 분포와 모델이 예측한 클래스의 일치 정도를 표현합니다. 실제 예측된 확률값은 물론 특정한 작업이 필요합니다. 이 작업은 뒤에서 보다 자세히 다루겠습니다. 먼저 예측된 확률을 평가하는 대표적인 두 가지 지표들을 살펴보겠습니다.</p><h3 id="logarithmic-loss-score">Logarithmic Loss Score</h3><hr /><p>명확한 이해를 위해서 고전적인 ‘동전 던지기’ 상황을 끌어오겠습니다. 이 상황은 다음과 같은 특징을 가집니다.</p><ul><li>일반적으로 한번 시도합니다.<li>동전을 던질 때 나올 수 있는 경우를 X라 할 때, X는 셀 수 있는 유한개의 경우의 수를 가지면서 각 사건이 독립일 것입니다.<li>다시 말해서 X는 앞(Head) 또는 뒤(Tail)일 것입니다. 그리고 각 개별 사건은 다른 사건들에 영향을 주지 않습니다.<li>\(P(H) + P(T) = 1\), where \(P(H) = p\)</ul><p><br /></p><p>위의 특징들은 다음과 같은 식으로 압축됩니다.</p><p><br /></p>\[X_{i} \sim iid \,Bernolli(p)\]<p><br /></p><p>또한 확률 질량 함수는 다음과 같습니다.</p><p><br /></p>\[P(X=x) = \begin{cases} p &amp; if \, X = Head \\ 1-p &amp; if \, X = Tail \\ 0 &amp; \text{otherwhise} \end{cases}\]<p>좀 더 간결히 표현해보겠습니다.</p>\[P(X=x) = \begin{cases} p^{x} \, \times \, (1-p)^{1-x} &amp; \text{if $X = Tail \, or \, Head$ } \\ 0 &amp; \text{otherwise} \end{cases}\]<p><br /></p><p>일정한 분포를 가지는 장기간의 R.V 산술 평균값을 확률 분포의 평균이라 정의할 때 특정 사건의 가능도는 아래와 같습니다.</p>\[\begin{aligned} E[X] &amp;= \sum_{x \in \mathbb{R}} {x \, \times \, P(X=x)} \\ &amp;= 1 \, \times \, P(X=1) + 0 \, \times \, P(X=0) \\ &amp;= 1 \, \times \, p + 0 \, \times \, (1-p) \\ &amp;= p \end{aligned}\]<p><br /></p><p>명시된 것들을 이탈 태스크에 적용해 보겠습니다. 예측 모델이 주어진 데이터를 통해 이탈 유무를 예측하는 것은 배반 사건이면서 독립 사건을 예측하는 경우입니다.</p><p><br /></p>\[P(Y=y|X) = \begin{cases} \hat{p} &amp; if \, y = \text{Churn} \\ 1-\hat{p} &amp; if \, y = \text{Not Churn} \\ \end{cases}\]<p><br /></p><p>표본 공간에서 주어진 데이터의 값들의 함수는 주어진 샘플과 같은 값을 가지는 R.V의 상대적인 가능도를 제공하는 역할을 하고 그 함수를 확률 밀도 함수라 명명합니다.</p><p>좋은 분류 모델은 \( \hat{p}\)와 \( p\)간의 차이가 크지 않습니다. 다시 말해서 \( p\)에 가장 가까운 추정치인 \( \hat{p}\)값이 높을 수록 성능이 우수한 모델입니다.</p><p><br /></p>\[\begin{aligned} L(\theta) &amp;= P(Y|X;\theta) \\ &amp;= \prod_{i=1}^{N(x)}P(y^{i} | x^{i}) \end{aligned}\]<p><br /></p><p>결국 \(\theta\)에 대한 가능도는 동전 던지기와 같은 상황이므로 베르누이 분포를 따릅니다.</p><p><br /></p>\[P(y^{i} | x^{i}) \sim iid \,Bernolli(\theta)\]<p><br /></p><p>확률 밀도 함수(f)는 각 사건이 독립이므로 개별 확률 밀도 함수의 곱으로 표현할 수 있습니다.</p>\[f(y_{1},y_{2},...,y_{N(x)}|\hat{p}) = p^{y_{1}} (1-\hat{p})^{1-y_{1}} \,\times \hat{p}^{y_{2}} (1-\hat{p})^{1-y_{2}} \,\times \, ... \,\times \hat{p}^{y_{N(x)}} (1-\hat{p})^{1-y_{N(x)}}\]<p><br /></p><p>가능도 함수를 이탈 확률(\( p\))로 편미분한 기울기값이 0일 때의 X값은 최적의 P일 것입니다. Log 함수가 단조 함수라는 것을 이용하여 가능도 함수를 변형하겠습니다.</p><p><br /></p>\[\begin{aligned} Log \,L &amp;= Log(\prod_{i =1}^{N(x)}\hat{p}^{y_{i}} (1-\hat{p})^{1-y_{i}}) \\ &amp;= \sum_{i=1}^{N(x)}log(\hat{p}^{y_{i}} (1-\hat{p})^{1-y_{i}}) \\ &amp;= \sum_{i=1}^{N(x)} y_{i}\,log(\hat{p}) + (1-y_{i}) \, log(1-\hat{p})\\ \end{aligned}\]<p><br /></p><p>위의 식에서는 gradient ascent 방식이지만 좌우변에 -를 붙히면 log-likelihood 함수를 최소화하는 경사 하강법을 적용할 수 있습니다.</p><p><br /></p>\[- Log \,L = \sum_{i=1}^{N(x)} -y_{i}\,log(\hat{p}) + (-1+y_{i}) \, log(1-\hat{p})\\\]<p><br /></p><p>평균적인 loss function 값을 갖는 Cost function은 다음과 같을 것입니다.</p><p><br /></p>\[Average(Log Loss) = \frac{1}{N(x)}\times \sum_{i=1}^{N(x)} -y_{i}\,log(\hat{p}) + (-1+y_{i}) \, log(1-\hat{p})\\\]<p><br /></p><p>지금까지 Log loss 함수는 이진 분류 모델이 예측한 확률값의 negative log likelihood를 계산한 결과임을 확인하였습니다. 식의 의미를 되짚어 보겠습니다. Log의 밑이 자연상수일 때 정보 이론<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>의 렌즈로 negative log likelihood를 바라보겠습니다. 모집단의 세계에서 알 수 있는 반응 변수에 대한 모분포(R) 정보를 현실에 주어진 데이터를 재료로 삼아 반응 변수를 추정한 분포(I) 정보를 통해 전달할 때 필요한 추가적인 정보량(비트 단위)일 것입니다.</p><p><br /></p><h3 id="brier-score">Brier Score</h3><hr /><ul><li>Brier score<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup>는 예측된 확률값들과 기댓값의 MSE(Mean Squared Error)를 계산한 지표입니다.<li>Threshold Metric중 Recall-Precision curve처럼 양성 클래스의 확률값에 초점을 맞춥니다.<li>다만 Recall-Precision curve와는 달리 다중 클래스에도 적용할 수 있습니다.</ul><p><br /></p>\[BS(Brier Score) = \frac{1}{N} \times \sum_{i=1}^{N}(\hat{y_{i}} - y_{i})^2\]<p><br /></p><p>확률의 첫번째 공리와 MSE 수식 자체의 특성이 결합되어 Brier Score는 굉장히 작은 값이 나올 가능성이 높습니다. 이런 문제점을 해결하기 위해서 Brier score를 베이스 라인 모델의 참고 점수(Reference score)를 사용하여 변형합니다.</p><p><br /></p>\[BrierSkillScore = 1 - \frac{Brier \, score}{Brier \, score[reference]}\]<p><br /></p><p>가상의 불균형 데이터를 만들어서 Brier Score를 살펴보겠습니다. 먼저 10000개 샘플에 관하여 두 가지 예측 변수들과 클래스가 0이거나 1인 클래스를 구성하겠습니다. 노이즈 데이터의 비율은 실험의 명확성을 위해 0으로 설정하였고 다수 클래스에 대한 가중치는 90%로 설정하였습니다. 그리고 y 클래스의 비율로 Stratified random sampling을 거치겠습니다.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
          <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mf">0.90</span><span class="p">],</span>
          <span class="n">n_features</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
          <span class="n">n_redundant</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
          <span class="n">n_clusters_per_class</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
          <span class="n">random_state</span> <span class="o">=</span> <span class="mi">33</span><span class="p">,</span>
          <span class="n">flip_y</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">unique_value</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">list_y</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">unique_value</span><span class="p">,</span> <span class="n">counts</span><span class="p">))</span>
<span class="p">{</span><span class="n">i</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="p">:</span> <span class="n">i</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">list_y</span><span class="p">}</span>    
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>{0: 9001, 1: 999}
</pre></table></code></div></div><p>모든 케이스를 ‘Negative’로 예측할 경우 Brier Score는 다음과 같습니다.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">all_negative_probs</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">testy</span><span class="p">))]</span>
<span class="n">brier_score</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">((</span><span class="n">testy</span> <span class="o">-</span> <span class="n">all_negative_probs</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'P(-) brier_score = '</span><span class="p">,</span> <span class="n">brier_score</span><span class="p">)</span>   
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>P(-) brier_score =  0.1
</pre></table></code></div></div><p>반면에 모든 케이스를 ‘Positive’로 예측할 경우 Brier Score는 다음과 같습니다.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">all_positive_probs</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">testy</span><span class="p">))]</span>
<span class="n">brier_score</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">((</span><span class="n">testy</span> <span class="o">-</span> <span class="n">all_positive_probs</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'P(+) brier_score = '</span><span class="p">,</span> <span class="n">brier_score</span><span class="p">)</span>  
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>P(+) brier_score =  0.9
</pre></table></code></div></div><p><br /></p><p>다음으로 Brier Skill Score를 살펴보겠습니다. 모든 확률이 0.1일 때를 가정한 값을 Reference Score로 설정하겠습니다. 그리고 모든 케이스를 ‘+’로 예측한 경우, 모든 케이스를 ‘-‘로 예측한 경우, 그리고 베이스라인 모델에 사용했던 0.1의 확률을 사용하여 BSS를 개별적으로 구하면 다음과 같습니다.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">refer_bss</span><span class="p">(</span><span class="n">prob_constant</span><span class="p">,</span><span class="n">ref_constant</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
    <span class="n">case_probs</span> <span class="o">=</span> <span class="p">[</span><span class="n">prob_constant</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">))]</span>
    <span class="n">ref_probs</span> <span class="o">=</span> <span class="p">[</span><span class="n">ref_constant</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">))]</span>
    <span class="n">case_bs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">((</span><span class="n">testy</span><span class="o">-</span><span class="n">case_probs</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">ref_bs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">((</span><span class="n">testy</span><span class="o">-</span><span class="n">ref_probs</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">case_bs</span><span class="o">/</span><span class="n">ref_bs</span><span class="p">)</span>
    
<span class="k">print</span><span class="p">(</span><span class="s">'Rererence brier skill score = '</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">refer_bss</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="n">testy</span><span class="p">),</span><span class="mi">4</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'P(-) brier skill score = '</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">refer_bss</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="n">testy</span><span class="p">),</span><span class="mi">4</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'P(+) brier skill score = '</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">refer_bss</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="n">testy</span><span class="p">),</span><span class="mi">4</span><span class="p">))</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>Rererence brier skill score =  0.0
P(-) brier skill score =  -0.1111
P(+) brier skill score =  -9.0
</pre></table></code></div></div><p><br /></p><h2 id="probability-calibration">Probability Calibration</h2><p>반응 변수의 분포가 심하게 왜곡된 경우 모델이 예측한 모델은 다수 클래스를 지나치게 선호하게 됩니다. 이런 경향을 완화하기 위해서 예측된 확률을 대상으로 Calibration을 적용합니다. 교정된 확률들은 실제 사건의 가능도를 반영합니다.</p><p>안타깝게도 Calibration이 적용된 모델은 아주 많지 않습니다. 대표적으로 MLE 추정을 활용한 Logistic Regression이 있습니다. Logistic regression의 cost function은 위에서 유도한 Log loss function을 사용하며 식은 다음과 같습니다[단, \( N_{x} = m\), \(\hat{p} = h_\theta\)]</p><p><br /></p>\[\begin{aligned} J(\theta) = -\frac{1}{m}\sum_{i=1}^m \left[ y^{(i)}\log\left(h_\theta \left(x^{(i)}\right)\right) + (1 -y^{(i)})\log\left(1-h_\theta \left(x^{(i)}\right)\right)\right] \end{aligned}\] \[where \, h_{\theta}(x^{(i)}) = \frac{1}{1+\exp[-\alpha -\sum_j \theta_j x^{(i)}_j]}\]<p><br /></p><p>Cost function을 최소화 하기 위해서 파라미터인 \( \theta_{j}\)로 편미분<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">3</a></sup>한 결과는 0입니다.</p><p><br /></p>\[\begin{aligned} \small \frac{\partial J(\theta)}{\partial \theta_j} = \frac{\partial}{\partial \theta_j} \,\frac{-1}{m}\sum_{i=1}^m \left[ y^{(i)}\log\left(h_\theta \left(x^{(i)}\right)\right) + (1 -y^{(i)})\log\left(1-h_\theta \left(x^{(i)}\right)\right)\right] \\[2ex]\small\underset{\text{linearity}}= \,\frac{-1}{m}\,\sum_{i=1}^m \left[ y^{(i)}\frac{\partial}{\partial \theta_j}\log\left(h_\theta \left(x^{(i)}\right)\right) + (1 -y^{(i)})\frac{\partial}{\partial \theta_j}\log\left(1-h_\theta \left(x^{(i)}\right)\right) \right] \\[2ex]\Tiny\underset{\text{chain rule}}= \,\frac{-1}{m}\,\sum_{i=1}^m \left[ y^{(i)}\frac{\frac{\partial}{\partial \theta_j}h_\theta \left(x^{(i)}\right)}{h_\theta\left(x^{(i)}\right)} + (1 -y^{(i)})\frac{\frac{\partial}{\partial \theta_j}\left(1-h_\theta \left(x^{(i)}\right)\right)}{1-h_\theta\left(x^{(i)}\right)} \right] \\[2ex]\small\underset{h_\theta(x)=\sigma\left(\theta^\top x\right)}=\,\frac{-1}{m}\,\sum_{i=1}^m \left[ y^{(i)}\frac{\frac{\partial}{\partial \theta_j}\sigma\left(\theta^\top x^{(i)}\right)}{h_\theta\left(x^{(i)}\right)} + (1 -y^{(i)})\frac{\frac{\partial}{\partial \theta_j}\left(1-\sigma\left(\theta^\top x^{(i)}\right)\right)}{1-h_\theta\left(x^{(i)}\right)} \right] \\[2ex]\Tiny\underset{\sigma'}=\frac{-1}{m}\,\sum_{i=1}^m \left[ y^{(i)}\, \frac{\sigma\left(\theta^\top x^{(i)}\right)\left(1-\sigma\left(\theta^\top x^{(i)}\right)\right)\frac{\partial}{\partial \theta_j}\left(\theta^\top x^{(i)}\right)}{h_\theta\left(x^{(i)}\right)} - (1 -y^{(i)})\,\frac{\sigma\left(\theta^\top x^{(i)}\right)\left(1-\sigma\left(\theta^\top x^{(i)}\right)\right)\frac{\partial}{\partial \theta_j}\left(\theta^\top x^{(i)}\right)}{1-h_\theta\left(x^{(i)}\right)} \right] \\[2ex]\small\underset{\sigma\left(\theta^\top x\right)=h_\theta(x)}= \,\frac{-1}{m}\,\sum_{i=1}^m \left[ y^{(i)}\frac{h_\theta\left( x^{(i)}\right)\left(1-h_\theta\left( x^{(i)}\right)\right)\frac{\partial}{\partial \theta_j}\left(\theta^\top x^{(i)}\right)}{h_\theta\left(x^{(i)}\right)} - (1 -y^{(i)})\frac{h_\theta\left( x^{(i)}\right)\left(1-h_\theta\left(x^{(i)}\right)\right)\frac{\partial}{\partial \theta_j}\left( \theta^\top x^{(i)}\right)}{1-h_\theta\left(x^{(i)}\right)} \right] \\[2ex]\small\underset{\frac{\partial}{\partial \theta_j}\left(\theta^\top x^{(i)}\right)=x_j^{(i)}}=\,\frac{-1}{m}\,\sum_{i=1}^m \left[y^{(i)}\left(1-h_\theta\left(x^{(i)}\right)\right)x_j^{(i)}- \left(1-y^{i}\right)\,h_\theta\left(x^{(i)}\right)x_j^{(i)} \right] \\[2ex]\small\underset{\text{distribute}}=\,\frac{-1}{m}\,\sum_{i=1}^m \left[y^{i}-y^{i}h_\theta\left(x^{(i)}\right)- h_\theta\left(x^{(i)}\right)+y^{(i)}h_\theta\left(x^{(i)}\right) \right]\,x_j^{(i)} \\[2ex]\small\underset{\text{cancel}}=\,\frac{-1}{m}\,\sum_{i=1}^m \left[y^{(i)}-h_\theta\left(x^{(i)}\right)\right]\,x_j^{(i)} \\[2ex]\small=\frac{1}{m}\sum_{i=1}^m\left[h_\theta\left(x^{(i)}\right)-y^{(i)}\right]\,x_j^{(i)} \\[2ex] \small= 0 \end{aligned}\]<p>식을 조금 정리해 주면 다음과 같이 재밌는 결과가 나옵니다.</p><p><br /></p>\[\sum_{i=1}^m h_\theta\left(x^{(i)}\right)x_j^{(i)}=\sum_{i=1}^m y^{(i)}\,x_j^{(i)}\]<p><br /></p><p>이러한 성질을 담보하지 않는 Tree 계열 모델들과 SVM은 교정된 확률을 가지지 못하기 때문에 이러한 모델의 예측값을 확률로 설정할 때는 반드시 Calibration을 인위적으로 적용해야 합니다.</p><p><br /></p><p>그래서 앞의 수식처럼 학습 데이터에서 관측된 분포와 모델의 예측 확률 값들의 집합이 잘 일치하도록 스케일링해야 합니다. 예측 확률들을 스케일링하는 방법은 크게 두 가지 입니다.</p><ul><li>Platt Scaling<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote" rel="footnote">4</a></sup><ul><li>Platt Scaling은 SVM의 예측 확률값들을 스케일링하기 위해 개발되었습니다. Logistic regression 모델에서 적용된 기법이 사용됩니다.</ul><li>Isotonic Regression<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" class="footnote" rel="footnote">5</a></sup><ul><li>가중치가 사용된 최소 제곱 회귀 모델입니다.<li>Platt Scaling에 비해 많은 데이터가 필요하지만 보다 더 일반화된 모델 성능을 얻을 수 있습니다.</ul></ul><p><br /></p><h2 id="reference">Reference</h2><div class="footnotes" role="doc-endnotes"><ol><li id="fn:1" role="doc-endnote"><p>https://en.wikipedia.org/wiki/Information_theory <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:2" role="doc-endnote"><p>https://en.wikipedia.org/wiki/Brier_score <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:3" role="doc-endnote"><p>https://stats.stackexchange.com/questions/278771/how-is-the-cost-function-from-logistic-regression-derivated/278812#278812 <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:4" role="doc-endnote"><p>https://en.wikipedia.org/wiki/Platt_scaling <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p><li id="fn:5" role="doc-endnote"><p>https://en.wikipedia.org/wiki/Isotonic_regression <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p></ol></div></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/ml/'>ML</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/imbalanced_data/" class="post-tag no-text-decoration" >Imbalanced_data</a> <a href="/tags/churn_prediction/" class="post-tag no-text-decoration" >Churn_prediction</a> <a href="/tags/classification/" class="post-tag no-text-decoration" >Classification</a> <a href="/tags/cost_sensitive/" class="post-tag no-text-decoration" >Cost_sensitive</a> <a href="/tags/evaluation_metric/" class="post-tag no-text-decoration" >Evaluation_metric</a> <a href="/tags/calibration/" class="post-tag no-text-decoration" >Calibration</a> <a href="/tags/probability_scoring/" class="post-tag no-text-decoration" >Probability_scoring</a> <a href="/tags/brier_score/" class="post-tag no-text-decoration" >Brier_score</a> <a href="/tags/logloss_score/" class="post-tag no-text-decoration" >Logloss_score</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Imbalanced data classification part2 - Kwon_sun_cheol&url=https://classicmania.github.io/posts/Imbalanced_classification_part2/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Imbalanced data classification part2 - Kwon_sun_cheol&u=https://classicmania.github.io/posts/Imbalanced_classification_part2/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Imbalanced data classification part2 - Kwon_sun_cheol&url=https://classicmania.github.io/posts/Imbalanced_classification_part2/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><h3 data-toc-skip class="pl-3 pt-2 mb-2">Contents</h3><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/Imbalanced_classification_part1/"><div class="card-body"> <span class="timeago small" > Jan 9 <i class="unloaded">2021-01-09T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Imbalanced data classification part1</h3><div class="text-muted small"><p> Cute imbalanced image1 지도학습에서 분류 문제를 다룰 때 Imbalanced classification인 경우가 많았습니다. 예를 들어 이커머스 데이터를 활용하여 개별적인 고객의 이탈을 예측하는 모델을 만들 때 위의 문제를 발견할 수 있었습니다. 실무에서 이탈 예측 태스크를 진행하면서 ‘불균형 데이터를 어떻게 다룰 것인가’에 대...</p></div></div></a></div><div class="card"> <a href="/posts/Similarityandmetrics/"><div class="card-body"> <span class="timeago small" > Apr 18 <i class="unloaded">2021-04-18T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Recommendation system for E-commerce / Similarity and Metrics</h3><div class="text-muted small"><p> 지난 시간에는 팀원들과 Matrix Completion과 관련된 SVD1, ALS2, SGD의 개념을 살펴보았습니다. 이번 시간에는 이커머스에서 추천 모델의 최종 단계인 유사도(Similarity)를 계산하는 부분과 지표(Metric)를 점검해보았습니다. Similarity 상품 또는 고객을 벡터로 표현한 뒤 벡터 간의 유사...</p></div></div></a></div><div class="card"> <a href="/posts/User2userItem2Item/"><div class="card-body"> <span class="timeago small" > Mar 21 <i class="unloaded">2021-03-21T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Recommendation system for E-commerce / Collaborative Filtering</h3><div class="text-muted small"><p> 현재 추천 시스템이 적용되고 있고 고도화를 진행하고 있는 시점에서 최근 팀원분들과 추천 스터디를 플립러닝(flipped learning) 방식으로 진행하게 되었습니다. 우선 팀원들과 함께 추천의 내재적인 부분과 기본적인 내용들을 확인하고 놓칠 수 있는 부분들을 점검하고 있습니다. 이번주는 팀원들과 함께 중소형 트래픽 규모를 가...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/Imbalanced_classification_part1/" class="btn btn-outline-primary"><p>Imbalanced data classification part1</p></a> <a href="/posts/SparkTuningPart1/" class="btn btn-outline-primary"><p>Spark Tuning과 관련된 몇 가지 발견들</p></a></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('#post-wrapper img'); const observer = lozad(imgs); observer.observe(); </script><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2021 <a href="https://github.com/classicmania">Kwon_suncheol</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy/">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-xl-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/similarity/">Similarity</a> <a class="post-tag" href="/tags/recommendation/">Recommendation</a> <a class="post-tag" href="/tags/imbalanced_data/">Imbalanced_data</a> <a class="post-tag" href="/tags/evaluation_metric/">Evaluation_metric</a> <a class="post-tag" href="/tags/data_sampling/">Data_sampling</a> <a class="post-tag" href="/tags/classification/">Classification</a> <a class="post-tag" href="/tags/churn_prediction/">Churn_prediction</a> <a class="post-tag" href="/tags/stack/">stack</a> <a class="post-tag" href="/tags/queue/">queue</a> <a class="post-tag" href="/tags/linked_list/">linked_list</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://classicmania.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"><div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>{categories}</div><div><i class="fa fa-tag fa-fw"></i>{tags}</div></div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>' }); </script>
